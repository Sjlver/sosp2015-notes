Holistic Configuration Management at Facebook
=============================================

A true story: at some point, profiling was enabled for all Facebook users by
mistake (should have been enabled for a small subset). This almost caused an
outage.

There are thousands of live configuration changes every day. Almost any engineer
can make them.

Solution:

- config authoring
- config error prevention
- config distribution


## 1. Configuration authoring

Facebook's configuration is strongly typed, looking somewhat like a C struct or
JSON file.

These are rarely edited by hand (75% are generated by the config compiler
described below. 22% are generated by other config tools, and 3% are edited
manually).

Median size is 1KB, 95th percentile is 65KB.

"Configuration as Code" approach (aka "Configerator"):

- configuration is produced programmatically (engineers write code to do so)
- configuration is validated (engineers write extra code to do this)

This is cool, because of code reuse. It makes the configuration modular. Studies
show that the code changes 60% less frequently than the actual configuration
files.

Configurations are often dependent: If e.g., a port is changed, then the
firewall config must also be modified. Having a modular programmatic
configuration with includes takes care of this.

Some sort of make-like mechanism is used to re-generate the affected files
whenever an include file changes.


## 2. Configuration error prevention

The compiler runs a validator when a configuration is changed, to verify
invariants.

In addition to that, there are mandatory manual tests, and automated integration
tests in a staging environment.

Code reviews are mandatory for both the configuration programs and the generated
config files.

Automated canary tests in production: Configurations are rolled out
progressively to increasing numbers of servers. This is valuable because staging
and production are never quite equal, and also because many configuration
settings have performance implications that only show up in production.

How effective is this?

In three months, 16% of the measured incidents are related to config changes. In
other companies, studies report ~29% of errors due to configuration.

Of these incidents,

- 42% were typos and trivial errors
- 32% were subtle errors (e.g., performance overloads or butterfly effects)
- 36% were cases where configuration changes exposed bugs in Facebook's
  code base (i.e., code bugs rather than configuration bugs).


## 3. Deploying the configuration

All the configuration is stored in a git repository.

A "tailer" extracts the configuration from this repo and replicates it to
ZooKeeper. The leader of this ZooKeeper ensemble then pushes the configuration
to every cluster.

Servers in the cluster use a publish/subscribe model, to get only the config
they need from their cluster's "observer". Servers cache configuration files on
disk, so that they continue working even if the configuration infrastructure is
down.

Some config files are very large (gigabytes). Examples are machine learning models.
These are stored in a storage systems, and only their metadata is checked into
git. Servers use a bittorrent-like system to obtain these large configurations.

The configuration grows quickly (there are many more config commits than code
commits, tendency increasing). It takes 10-40 seconds to push a config change.
Git is the main bottleneck here.
